{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pidipidi/cs470_IAI/blob/main/tutorial_2/tutorial2_quiz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "fdSOfUuN4w8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Please run this tutorial on Google Chrome.\n",
        "\n",
        "[https://www.google.com/chrome](https://www.google.com/chrome)\n",
        "\n",
        "\n",
        "The tutorial may not work properly if you use a browser other than Google Chrome"
      ],
      "metadata": {
        "id": "xCTRK3XdfR-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run the following commands to install dependencies\n",
        "#Install dependencies for OpenAI Gym and Stable-baselines3\n",
        "!apt install swig cmake &> /dev/null\n",
        "!pip install stable-baselines3[extra] box2d box2d-kengz &> /dev/null\n",
        "!pip install gym==0.24.0 gym[classic_control] &> /dev/null\n",
        "\n",
        "#Install dependencies to visualize agents\n",
        "!apt-get install -y xvfb python-opengl x11-utils &> /dev/null\n",
        "!pip install pyvirtualdisplay scikit-video ffio pyrender &> /dev/null\n",
        "import os\n",
        "os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "KRS9SfsG3DF_",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run the following commands to define visualization tools\n",
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "import skvideo.io\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()\n",
        "def save_video_of_model(env_name, policy=None, suffix=\"\"):\n",
        "    \"\"\"Record an agent behavior in an input environment\"\"\"\n",
        "\n",
        "    env = gym.make(env_name)\n",
        "    obs = env.reset()\n",
        "    prev_obs = obs\n",
        "\n",
        "    filename = env_name + suffix + \".mp4\"\n",
        "    output_video = skvideo.io.FFmpegWriter(filename)\n",
        "\n",
        "    counter = 0\n",
        "    done = False\n",
        "    if hasattr(env, \"render_mode\"):\n",
        "        env.render_mode=\"rgb_array\"\n",
        "    while not done:\n",
        "        frame = env.render(mode='rgb_array')\n",
        "        output_video.writeFrame(frame)\n",
        "\n",
        "        input_obs = obs\n",
        "\n",
        "        if policy is not None:\n",
        "            # action, _ = policy(input_obs)\n",
        "            action = policy(input_obs)\n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "\n",
        "        if \"FrozenLake\" in env_name:\n",
        "            action = action.item()\n",
        "        prev_obs = obs\n",
        "        \n",
        "        obs, reward, done, info = env.step(action)\n",
        "        counter += 1\n",
        "\n",
        "    output_video.close()\n",
        "    print(\"Successfully saved {} frames into {}!\".format(counter, filename))\n",
        "    return filename\n",
        "\n",
        "def play_video(filename, width=None):\n",
        "    \"\"\"Play the filename of video\"\"\"\n",
        "    from IPython.display import HTML\n",
        "    from base64 import b64encode\n",
        "    \n",
        "    mp4 = open(filename,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    source = \"\"\"\n",
        "    <video width=400 controls>\n",
        "          <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url\n",
        "    return source\n",
        "\n",
        "\n",
        "from gym import register\n",
        "if 'FrozenLake-v0' in gym.envs.registration.registry.env_specs:\n",
        "  del gym.envs.registration.registry.env_specs['FrozenLake-v0']\n",
        "register(\n",
        "    id=\"FrozenLake-v0\",\n",
        "    entry_point=\"gym.envs.toy_text.frozen_lake:FrozenLakeEnv\",\n",
        "    kwargs={\"map_name\": \"4x4\", \"is_slippery\": False},\n",
        "    max_episode_steps=100,\n",
        "    reward_threshold=1.0,\n",
        ")\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "\n",
        "def my_seed_everywhere(seed: int = 42):\n",
        "    random.seed(seed) # random\n",
        "    np.random.seed(seed) # numpy\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed) # os\n",
        "    # pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed) \n",
        "    torch.backends.cudnn.deterministic = True \n",
        "    torch.backends.cudnn.benchmark = False \n",
        "\n",
        "my_seed = 42\n",
        "my_seed_everywhere(my_seed)"
      ],
      "metadata": {
        "id": "GhmNo6uu-Z4c",
        "cellView": "form",
        "outputId": "75bb5f97-cf3f-49bc-b35a-2ec14030e42c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make sure you are using 0.24.0 version of gym."
      ],
      "metadata": {
        "id": "illneNVj7quZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show gym"
      ],
      "metadata": {
        "id": "9TtLDtFe7FVr",
        "outputId": "7934d547-128a-4f1d-e789-27f3ab34ecd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: gym\n",
            "Version: 0.24.0\n",
            "Summary: Gym: A universal API for reinforcement learning environments\n",
            "Home-page: https://www.gymlibrary.ml/\n",
            "Author: Gym Community\n",
            "Author-email: jkterry@umd.edu\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: gym-notices, numpy, cloudpickle, importlib-metadata\n",
            "Required-by: stable-baselines3, dopamine-rl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CartPole-v0 environment"
      ],
      "metadata": {
        "id": "61wEJLl31hC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this quiz, we will use CartPole-v0 environment. This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson in “Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem”. A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum is placed upright on the cart and the goal is to balance the pole by applying forces in the left and right direction on the cart.\n",
        "\n",
        "https://www.gymlibrary.dev/environments/classic_control/cart_pole/"
      ],
      "metadata": {
        "id": "-5lEqvTp1zTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cp.gif](data:image/gif;base64,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)"
      ],
      "metadata": {
        "id": "YtJJKTe01qHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Please choose the pair that properly describes the class of (observation_space, action_space) of \"CartPole-v0\".\n",
        "\n",
        "\n",
        "\n",
        "1.   (Discrete, Discrete)\n",
        "2.   (Box, Discrete)\n",
        "3.   (Discrete, Box)\n",
        "4.   (Box, Box)\n",
        "\n",
        "\n",
        "You may use the cell below to find the answer"
      ],
      "metadata": {
        "id": "2nrkHYAdOXZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "\n",
        "print( ... )"
      ],
      "metadata": {
        "id": "SpgvdK9G5KWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Please choose the pair that properly fills in the sentence.\n",
        "\n",
        "We use {$\\qquad$} method to initialize or restart the environment. If we initialize \"CartPole-v0\" environment, each element of the initial state fall within {$\\qquad$} range.\n",
        "\n",
        "\n",
        "1.   (step, [-0.05, 0.05])\n",
        "2.   (reset, [0.05, 0.05])\n",
        "3.   (reset, [-0.01, 0.01])\n",
        "4.   (render, [-0.01, 0.01])\n",
        "\n",
        "\n",
        "You may use the cell below to find the answer"
      ],
      "metadata": {
        "id": "xKXq15FUGo_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "439qmdPeGo2p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Please choose the answer that correctly estimates the maximum total reward of \"CartPole-v0\" environment.\n",
        "\n",
        "\n",
        "1.   ~100\n",
        "2.   ~200\n",
        "3.   ~500\n",
        "4.   ~700\n",
        "\n",
        "\n",
        "You may use the cell below to find the answer.\n",
        "\n",
        "You may increase (decrease) the total_timestep value if you think the agent has not trained enough (has trained enough)."
      ],
      "metadata": {
        "id": "LJ-piSTT0gyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import stable_baselines3\n",
        "from stable_baselines3 import PPO, DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "######################################################################\n",
        "##  You can choose your Algorithm / Environment / seed as you want  ##\n",
        "######################################################################\n",
        "\n",
        "policy_cls = ...\n",
        "env_id = \"CartPole-v0\"\n",
        "SEED = 47\n",
        "\n",
        "######################################################################\n",
        "######################################################################\n",
        "\n",
        "\n",
        "# Use a separate environement for evaluation\n",
        "env = gym.make(env_id)\n",
        "eval_env = gym.make(env_id)\n",
        "# Initialize Agent, which is currently an random Agent, before training\n",
        "model = policy_cls(policy='MlpPolicy',      # For vision-based RL, we use 'CnnPolicy'\n",
        "            env=env, \n",
        "            seed=SEED, \n",
        "            gamma=0.9)"
      ],
      "metadata": {
        "id": "KaI-zqzy5oQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps, EvalCallback\n",
        "\n",
        "rewards = []\n",
        "class CB(EvalCallback):\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.eval_freq == 0:\n",
        "            mean_reward, std_reward = evaluate_policy(self.model, self.eval_env, n_eval_episodes=5)\n",
        "            rewards.append(mean_reward)\n",
        "            print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "        return True\n",
        "\n",
        "cb = CB(eval_env=eval_env, eval_freq=10000)\n",
        "model.learn(total_timesteps=100000, callback=cb)\n"
      ],
      "metadata": {
        "id": "cVlwqTeMZzip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "id": "CB13iS3c0X3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_video_of_model(env_id, policy=lambda *x: model.predict(*x)[0])\n",
        "\n",
        "from IPython.display import HTML\n",
        "source = play_video(filename=f'{env_id}.mp4')\n",
        "HTML(source)"
      ],
      "metadata": {
        "id": "b5aRRAhvbH8n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}