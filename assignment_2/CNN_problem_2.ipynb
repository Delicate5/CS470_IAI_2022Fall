{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSuVSNspPs4f"
      },
      "source": [
        "# **CS 470 Assignment 2** \n",
        "\n",
        "#2. Convolutional Neural Networks (CNN) using PyTorch \n",
        "\n",
        "#### In this assignment, you will develop a neural network with convolution and pooling layers to perform image classification, and test it out on the [CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html) dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq22uftGvsR4"
      },
      "outputs": [],
      "source": [
        "#Importing all libraries\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wWxsXO7PyfT"
      },
      "source": [
        "## Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITDbKtgGfcPa"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [40000, 10000])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=8)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=128, shuffle=False, num_workers=8)\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=8)\n",
        "\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_2DjMXgzLGz"
      },
      "source": [
        "## Visualize 10 different classes of images in the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-afxRYXEffJx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# visualize training image for each class\n",
        "sample_images = [dataset.data[np.asarray(dataset.targets) == label][0] for label in range(10)]\n",
        "# show images\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "i = 0\n",
        "for row in axes:\n",
        "  for axis in row:\n",
        "    axis.set_xticks([])\n",
        "    axis.set_yticks([])\n",
        "    axis.set_xlabel(classes[i], fontsize=15)\n",
        "    axis.imshow(sample_images[i])\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqwB3E1GU1XS"
      },
      "source": [
        "## Design your convolutional neural network\n",
        "\n",
        "In PyTorch, there are built-in functions that carry out the convolution steps for you. The following shows the key functions required for the design.\n",
        "\n",
        "\n",
        "*   nn.**Conv2d**(in_channels, out_channels, kernel_size, stride=1, padding=0):<br>\n",
        "Convolution layer. You can read the full documentation [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) \n",
        "*   nn.**MaxPool2d**(kernel_size, stride=None, padding=0): <br>\n",
        "Max pooling layer. You can read the full documentation [here](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) \n",
        "*   F.**relu**(Z1): <br>\n",
        "computes the elementwise ReLU of Z1 (which can be any shape). You can read the full documentation [here](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) \n",
        "*   x.**view**(new_shape):<br> \n",
        "Returns a new tensor with the same data but different size. It is the equivalent of numpy function reshape (Gives a new shape to an array without changing its data). You can read the full documentation [here](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) \n",
        "*   nn.**Linear**(in_features, out_features): <br>\n",
        "Applies a linear transformation to the incoming data. It is also called a fully connected layer. You can read the full documentation [here](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) \n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyEoUgQH83AC"
      },
      "source": [
        "## a. Convolution and MaxPooling layers\n",
        "### Design the model\n",
        "In this part, you will implement a CNN model described in 2.a. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDoOISiD-j-y"
      },
      "source": [
        "### Train the designed model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzWwNSgD6PjM"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Problem 1: Implementing your own CNN\n",
        "# a. Convolution and Adaptive AvgPooling layers\n",
        "# CNN architecture: 4 Convolution layers, 2 Pooling layers, 1 ReLU layer, 2 Linear layers\n",
        "\n",
        "class CNN_Max(nn.Module):\n",
        "  \"\"\"\n",
        "  A convolutional neural network (CNN). In this CNN object, we will use following\n",
        "  dimensions:\n",
        "\n",
        "  input_size: the dimension d of the input data.                        \n",
        "  hidden_size: the number of neurons h in the hidden layer.             \n",
        "  output_size: the number of classes c, which is 10 in our task          \n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    An initialization function. This object of network is a simple feed-forward \n",
        "    network. It takes an input to pass to muitiple layers. Then, provide the \n",
        "    output. The layers are initialized after their creation. \n",
        "\n",
        "    In this problem, we will use following set of parameters building a CNN/\n",
        "\n",
        "    conv: convolutional kernel size, which is 3 by 3                          \n",
        "    pool: pooling kernel-size, which is 2 by 2                                \n",
        "    fc: fully-connected layer which uses affine operation y=Wx+b              \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    N/A\n",
        "    \"\"\"\n",
        "    super(CNN_Max(, self).__init__()\n",
        "\n",
        "    #############################################################################\n",
        "    # PLACE YOUR CODE HERE                                                      #\n",
        "    ############################################################################# \n",
        "\n",
        "    # END OF YOUR CODE                                                          #\n",
        "    #############################################################################\n",
        "   \n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    A forward pass function. Using the pre-defined network modules, we can here \n",
        "    build a model designing its structure. \n",
        "\n",
        "    Parameters\n",
        "    ---------- \n",
        "    x: matrix  \n",
        "      an input data of shape (3, d, d), where d is the dimension of the input \n",
        "      image. Note that we use RGB images so channels are 3.\n",
        "  \n",
        "    Returns\n",
        "    ---------- \n",
        "    out:     \n",
        "      an output data given x.\n",
        "\n",
        "    \"\"\"\n",
        "    #############################################################################\n",
        "    # PLACE YOUR CODE HERE                                                      #\n",
        "    ############################################################################# \n",
        "  \n",
        "    # END OF YOUR CODE                                                          #\n",
        "    #############################################################################\n",
        "\n",
        "    return out\n",
        "\n",
        "# create a CNN object\n",
        "net = CNN_Max(()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:', device)\n",
        "net.to(device)\n",
        "\n",
        "num_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters:\", num_params)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Print out the overall architecture of the model\n",
        "\n",
        "\"\"\"\n",
        "#############################################################################\n",
        "# PLACE YOUR CODE HERE                                                      #\n",
        "############################################################################# \n",
        "  \n",
        "# END OF YOUR CODE                                                          #\n",
        "#############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3dOd3AT8KVK"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\"\"\"\n",
        "\n",
        " You have to define the loss, for that please use cross entropy loss      \n",
        " Also, you must implement optimizer called SGD with Momentum.                           \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#############################################################################\n",
        "# PLACE YOUR CODE HERE                                                      #\n",
        "############################################################################# \n",
        "\n",
        "#############################################################################\n",
        "#                              END OF YOUR CODE                             #\n",
        "#############################################################################\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True, min_lr=0)\n",
        "\n",
        "loss_hist, acc_hist = [], []\n",
        "loss_hist_val, acc_hist_val = [], []\n",
        "\n",
        "for epoch in range(50):\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  for data in train_loader:\n",
        "    batch, labels = data\n",
        "    batch, labels = batch.to(device), labels.to(device)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    First, set the gradients to zero. Then obtain predictions from your CNN   \n",
        "    model. After that, pass into loss to calculate the difference between the \n",
        "    prediction and labels. Next, you have to compute the gradients with       \n",
        "    respect to the tensor.  \n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "#############################################################################\n",
        "# PLACE YOUR CODE HERE                                                      #\n",
        "############################################################################# \n",
        "\n",
        "#############################################################################\n",
        "#                              END OF YOUR CODE                             #\n",
        "#############################################################################\n",
        "    optimizer.step()\n",
        "\n",
        "    # compute training statistics\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  avg_loss = running_loss / len(train_set)\n",
        "  avg_acc = correct / len(train_set)\n",
        "  loss_hist.append(avg_loss)\n",
        "  acc_hist.append(avg_acc)\n",
        "\n",
        "  # validation statistics\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "    loss_val = 0.0\n",
        "    correct_val = 0\n",
        "    for data in val_loader:\n",
        "      batch, labels = data\n",
        "      batch, labels = batch.to(device), labels.to(device)\n",
        "      outputs = net(batch)\n",
        "      loss = criterion(outputs, labels)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct_val += (predicted == labels).sum().item()\n",
        "      loss_val += loss.item()\n",
        "    avg_loss_val = loss_val / len(val_set)\n",
        "    avg_acc_val = correct_val / len(val_set)\n",
        "    loss_hist_val.append(avg_loss_val)\n",
        "    acc_hist_val.append(avg_acc_val)\n",
        "  net.train()\n",
        "\n",
        "  scheduler.step(avg_loss_val)\n",
        "  print('[epoch %d] loss: %.5f accuracy: %.4f val loss: %.5f val accuracy: %.4f' % (epoch + 1, avg_loss, avg_acc, avg_loss_val, avg_acc_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5So2DvVI8N_4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "  You have to plot a single plot for accuracy of training and validation data.              \n",
        "  Set x-axis to number of epochs and y-axis to accuracy. Set legend \n",
        "  equal to training and validation set.                                       \n",
        "\n",
        "\"\"\"\n",
        "#############################################################################\n",
        "# PLACE YOUR CODE HERE                                                      #\n",
        "############################################################################# \n",
        "\n",
        "#############################################################################\n",
        "#                              END OF YOUR CODE                             #\n",
        "#############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XQOl6fYQy5g"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "torch.save(net.state_dict(), 'checkpoint.pth')\n",
        "# download checkpoint file\n",
        "files.download('checkpoint.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRKMl8FcQzjt"
      },
      "outputs": [],
      "source": [
        "pred_vec = []\n",
        "correct = 0\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        batch, labels = data\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "        outputs = net(batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        pred_vec.append(predicted)\n",
        "    pred_vec = torch.cat(pred_vec)\n",
        "\n",
        "print('Accuracy on the 10000 test images: %.2f %%' % (100 * correct / len(test_set)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}